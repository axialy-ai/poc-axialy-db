name: Axialy DB AWS

on:
  workflow_dispatch:
    inputs:
      db_identifier:
        required: true
        default: axialy-database-cluster
      aws_region:
        required: true
        default: us-west-1
      instance_class:
        required: true
        default: db.t3.micro
      allocated_storage:
        required: true
        default: "20"

      # â”€â”€ Toggle flags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      cleanup_after_run:
        description: "Destroy the stack once the run is finished (OptionÂ A)"
        type: boolean
        default: false
      import_existing:
        description: "Try to import any preâ€‘existing resources (OptionÂ B)"
        type: boolean
        default: true

env:
  # These are still referenced inside steps, so expose globally
  AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

###############################################################################
# 1)  PREPARE â€“Â region validation, creds, backend guarantee, hygiene cleanup
###############################################################################
jobs:
  prepare:
    runs-on: ubuntu-latest

    outputs:
      aws_region:   ${{ steps.region.outputs.aws_region }}
      tf_bucket:    ${{ steps.state.outputs.tf_bucket }}
      tf_lock_tbl:  ${{ steps.state.outputs.tf_lock_tbl }}

    steps:
      - uses: actions/checkout@v4

      # â”€â”€ RegionÂ normaliser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Normalise AWS region input
        id: region
        shell: bash
        run: |
          REGION_IN="${{ github.event.inputs.aws_region }}"
          REGION_CLEAN="$(printf '%s' "$REGION_IN" | tr 'â€“â€”âˆ’â€‘' '-')"
          [[ "$REGION_CLEAN" =~ ^[a-z]{2}-[a-z]+-[0-9]+$ ]] \
            || { echo "::error::Invalid AWS region"; exit 1; }

          echo "AWS_REGION=$REGION_CLEAN"          >> "$GITHUB_ENV"
          echo "AWS_DEFAULT_REGION=$REGION_CLEAN"  >> "$GITHUB_ENV"
          echo "aws_region=$REGION_CLEAN"          >> "$GITHUB_OUTPUT"

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ steps.region.outputs.aws_region }}

      # â”€â”€ S3 & DynamoDB backend (and surface as job outputs) â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Ensure remoteâ€‘state backend exists
        id: state
        shell: bash
        run: |
          BUCKET=axialy-tf-state
          LOCK_TABLE=axialy-tf-lock

          aws s3 mb "s3://${BUCKET}" 2>/dev/null || true
          aws dynamodb create-table \
              --table-name "$LOCK_TABLE" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema            AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST 2>/dev/null || true

          # Expose to downstream jobs
          echo "TF_BUCKET=$BUCKET"     >> "$GITHUB_ENV"
          echo "TF_LOCK_TABLE=$LOCK_TABLE" >> "$GITHUB_ENV"
          echo "tf_bucket=$BUCKET"     >> "$GITHUB_OUTPUT"
          echo "tf_lock_tbl=$LOCK_TABLE" >> "$GITHUB_OUTPUT"

      # â”€â”€ Preâ€‘flight hygiene to dodge quota / AlreadyExists issues â”€â”€
      - name: Preâ€‘flight cleanup (orphan VPCs, EIPs, SSM params)
        shell: bash
        run: |
          set -euo pipefail

          echo "::group::Purging orphan Axialy VPCs"
          for vpc in $(aws ec2 describe-vpcs \
                     --filters "Name=tag:Name,Values=axialy-*" \
                               "Name=tag:ManagedBy,Values=terraform" \
                     --query 'Vpcs[].VpcId' --output text)
          do
            echo "ğŸ—‘ï¸  Deleting VPC $vpc"
            # Tear down NAT gateways first (they hold the EIPs)
            for ngw in $(aws ec2 describe-nat-gateways --filter Name=vpc-id,Values=$vpc \
                         --query 'NatGateways[].NatGatewayId' --output text); do
              aws ec2 delete-nat-gateway --nat-gateway-id "$ngw" || true
            done
            sleep 10
            # IGWs
            for igw in $(aws ec2 describe-internet-gateways \
                        --filters Name=attachment.vpc-id,Values=$vpc \
                        --query 'InternetGateways[].InternetGatewayId' --output text); do
              aws ec2 detach-internet-gateway --internet-gateway-id "$igw" --vpc-id "$vpc" || true
              aws ec2 delete-internet-gateway  --internet-gateway-id "$igw" || true
            done
            # Subnets
            for subnet in $(aws ec2 describe-subnets --filters Name=vpc-id,Values=$vpc \
                          --query 'Subnets[].SubnetId' --output text); do
              aws ec2 delete-subnet --subnet-id "$subnet" || true
            done
            # Route tables (nonâ€‘main)
            for rtb in $(aws ec2 describe-route-tables --filters Name=vpc-id,Values=$vpc \
                          --query 'RouteTables[?Associations[?Main==`false`]].RouteTableId' --output text); do
              aws ec2 delete-route-table --route-table-id "$rtb" || true
            done
            aws ec2 delete-vpc --vpc-id "$vpc" || true
          done
          echo "::endgroup::"

          echo "::group::Releasing orphan Axialy NAT EIPs"
          for alloc in $(aws ec2 describe-addresses \
                       --filters "Name=tag:Name,Values=axialy-nat-eip-* " \
                       --query 'Addresses[].AllocationId' --output text); do
            aws ec2 release-address --allocation-id "$alloc" || true
          done
          echo "::endgroup::"

          echo "::group::Deleting leftover SSM parameters"
          for p in host port user password; do
            aws ssm delete-parameter --name "/axialy/database/${p}" 2>/dev/null || true
          done
          echo "::endgroup::"

###############################################################################
# 2)  DEPLOY â€“Â create / update the entire stack (Terraform apply)
###############################################################################
  deploy:
    needs: prepare
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION:            ${{ needs.prepare.outputs.aws_region }}
      AWS_DEFAULT_REGION:    ${{ needs.prepare.outputs.aws_region }}
      TF_BUCKET:             ${{ needs.prepare.outputs.tf_bucket }}
      TF_LOCK_TABLE:         ${{ needs.prepare.outputs.tf_lock_tbl }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init
        working-directory: infra/database-aws
        run: |
          cat > backend.tf <<EOF
          terraform {
            backend "s3" {
              bucket         = "${TF_BUCKET}"
              key            = "database-aws/terraform.tfstate"
              region         = "${AWS_REGION}"
              dynamodb_table = "${TF_LOCK_TABLE}"
              encrypt        = true
            }
          }
          EOF
          terraform init -input=false

      # â”€â”€ (OptionÂ B) Import any preâ€‘existing pieces â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Import existing resources (if enabled)
        if: ${{ github.event.inputs.import_existing }}
        working-directory: infra/database-aws
        shell: bash
        run: |
          set -euo pipefail
          DB_ID="${{ github.event.inputs.db_identifier }}"

          imp () {
            local addr=$1 id=$2
            if ! terraform state list | grep -q "^$addr$"; then
              echo "â€º importing $addr ($id)"
              terraform import "$addr" "$id" || true
            fi
          }

          # Subnetâ€‘group
          aws rds describe-db-subnet-groups \
              --db-subnet-group-name axialy-db-subnet-group >/dev/null 2>&1 \
              && imp aws_db_subnet_group.axialy axialy-db-subnet-group

          # Log groups
          for lg in error general slowquery; do
            NAME="/aws/rds/instance/${DB_ID}/${lg}"
            aws logs describe-log-groups \
                 --log-group-name-prefix "$NAME" | jq -e '.logGroups|length>0' >/dev/null 2>&1 \
                 && imp "aws_cloudwatch_log_group.rds_${lg}" "$NAME"
          done

          # NATÂ EIPs
          for i in 1 2; do
            ALLOC=$(aws ec2 describe-addresses \
                      --filters "Name=tag:Name,Values=axialy-nat-eip-${i}" \
                      --query 'Addresses[0].AllocationId' --output text 2>/dev/null || true)
            [ "$ALLOC" != "None" ] && imp "aws_eip.nat[$((i-1))]" "$ALLOC"
          done

          # KMS alias (prevent AlreadyExistsException)
          if aws kms list-aliases \
               --query 'Aliases[?AliasName==`alias/axialy-rds`].AliasName' --output text | grep -q 'alias/axialy-rds'; then
            ARN=$(aws kms list-aliases \
                    --query 'Aliases[?AliasName==`alias/axialy-rds`].AliasArn' --output text)
            imp aws_kms_alias.rds "$ARN"
          fi

      # â”€â”€ Terraform apply â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Terraform apply
        id: tfout
        working-directory: infra/database-aws
        run: |
          terraform apply -auto-approve -input=false \
            -var="db_identifier=${{ github.event.inputs.db_identifier }}" \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="instance_class=${{ github.event.inputs.instance_class }}" \
            -var="allocated_storage=${{ github.event.inputs.allocated_storage }}"

          echo "db_endpoint=$(terraform output -raw db_endpoint)"            >> "$GITHUB_OUTPUT"
          echo "db_port=$(terraform output -raw db_port)"                    >> "$GITHUB_OUTPUT"
          echo "db_admin_user=$(terraform output -raw db_admin_user)"        >> "$GITHUB_OUTPUT"
          echo "db_admin_password=$(terraform output -raw db_admin_password)" >> "$GITHUB_OUTPUT"

###############################################################################
# 3)  CLEANUP â€“ optional autoâ€‘destroy when cleanup_after_run=true
###############################################################################
  cleanup:
    if: ${{ github.event.inputs.cleanup_after_run }}
    needs: [prepare, deploy]
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION:            ${{ needs.prepare.outputs.aws_region }}
      AWS_DEFAULT_REGION:    ${{ needs.prepare.outputs.aws_region }}
      TF_BUCKET:             ${{ needs.prepare.outputs.tf_bucket }}
      TF_LOCK_TABLE:         ${{ needs.prepare.outputs.tf_lock_tbl }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init (remote state)
        working-directory: infra/database-aws
        run: |
          cat > backend.tf <<EOF
          terraform {
            backend "s3" {
              bucket         = "${TF_BUCKET}"
              key            = "database-aws/terraform.tfstate"
              region         = "${AWS_REGION}"
              dynamodb_table = "${TF_LOCK_TABLE}"
              encrypt        = true
            }
          }
          EOF
          terraform init -input=false

      - name: Destroy stack
        working-directory: infra/database-aws
        run: terraform destroy -auto-approve -input=false
