name: Axialy DB AWS
on:
  workflow_dispatch:
    inputs:
      db_identifier:
        required: true
        default: axialy-database-cluster
      aws_region:
        required: true
        default: us-west-1
      instance_class:
        required: true
        default: db.t3.micro
      allocated_storage:
        required: true
        default: "20"
      #
      # ── NEW toggles ────────────────────────────────────────────────
      #
      cleanup_after_run:
        description: "Destroy the stack (Option A)"
        type: boolean
        default: false
      import_existing:
        description: "Auto‑import pre‑existing resources (Option B)"
        type: boolean
        default: true

env:
  AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

jobs:

# ─────────────────────────────────────────────────────────────
# 1)  Deploy / update the stack (state is held in S3 so it’s
#     always idempotent).
# ─────────────────────────────────────────────────────────────
  deploy:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Normalise AWS region input
        id: region
        shell: bash
        run: |
          REGION_IN="${{ github.event.inputs.aws_region }}"
          REGION_CLEAN="$(printf "%s" "$REGION_IN" | tr '–—−‑' '-')"
          [[ "$REGION_CLEAN" =~ ^[a-z]{2}-[a-z]+-[0-9]+$ ]] \
            || { echo "::error::Invalid AWS region"; exit 1; }
          echo "AWS_REGION=$REGION_CLEAN"          >> "$GITHUB_ENV"
          echo "AWS_DEFAULT_REGION=$REGION_CLEAN"  >> "$GITHUB_ENV"

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Ensure remote‑state bucket & lock table exist
        shell: bash
        run: |
          BUCKET=axialy-tf-state
          LOCK_TABLE=axialy-tf-lock
          aws s3 mb "s3://$BUCKET"      2>/dev/null || true
          aws dynamodb create-table \
            --table-name "$LOCK_TABLE"  \
            --attribute-definitions  AttributeName=LockID,AttributeType=S \
            --key-schema            AttributeName=LockID,KeyType=HASH     \
            --billing-mode PAY_PER_REQUEST 2>/dev/null || true
          echo "TF_BUCKET=$BUCKET"          >> "$GITHUB_ENV"
          echo "TF_LOCK_TABLE=$LOCK_TABLE"  >> "$GITHUB_ENV"

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init
        working-directory: infra/database-aws
        run: |
          cat > backend.tf <<EOF
          terraform {
            backend "s3" {
              bucket         = "${TF_BUCKET}"
              key            = "database-aws/terraform.tfstate"
              region         = "${AWS_REGION}"
              dynamodb_table = "${TF_LOCK_TABLE}"
              encrypt        = true
            }
          }
          EOF
          terraform init -input=false

      # ── Option B – import resources that may already exist ─────────
      - name: Import existing resources (if enabled)
        if: ${{ inputs.import_existing }}
        shell: bash
        working-directory: infra/database-aws
        run: |
          set -euo pipefail
          DB_ID="${{ github.event.inputs.db_identifier }}"

          # helper – import if it exists & isn’t already in state
          imp () {
            local addr=$1 id=$2
            if ! terraform state list | grep -q "^$addr$"; then
              echo "› importing $addr ($id)"
              terraform import "$addr" "$id" || true
            fi
          }

          # DB subnet‑group
          if aws rds describe-db-subnet-groups \
                --db-subnet-group-name axialy-db-subnet-group >/dev/null 2>&1; then
            imp aws_db_subnet_group.axialy axialy-db-subnet-group
          fi

          # CloudWatch log groups
          for lg in error general slowquery; do
            NAME="/aws/rds/instance/${DB_ID}/${lg}"
            if aws logs describe-log-groups \
                  --log-group-name-prefix "$NAME" | jq -e '.logGroups|length>0' >/dev/null; then
              imp "aws_cloudwatch_log_group.rds_${lg}" "$NAME"
            fi
          done

          # orphaned EIPs (named the same) → import instead of re‑create
          for i in 1 2; do
            ALLOC=$(aws ec2 describe-addresses \
                     --filters "Name=tag:Name,Values=axialy-nat-eip-${i}" \
                     --query 'Addresses[0].AllocationId' --output text 2>/dev/null || true)
            [ "$ALLOC" != "None" ] && imp "aws_eip.nat[${i-1}]" "$ALLOC"
          done

      - name: Terraform apply
        id: tfout
        working-directory: infra/database-aws
        run: |
          terraform apply -auto-approve -input=false \
            -var="db_identifier=${{ github.event.inputs.db_identifier }}" \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="instance_class=${{ github.event.inputs.instance_class }}" \
            -var="allocated_storage=${{ github.event.inputs.allocated_storage }}"

          echo "db_endpoint=$(terraform output -raw db_endpoint)"        >> "$GITHUB_OUTPUT"
          echo "db_port=$(terraform output -raw db_port)"                >> "$GITHUB_OUTPUT"
          echo "db_admin_user=$(terraform output -raw db_admin_user)"    >> "$GITHUB_OUTPUT"
          echo "db_admin_password=$(terraform output -raw db_admin_password)" >> "$GITHUB_OUTPUT"

# ─────────────────────────────────────────────────────────────
# 2)  *Optional* automatic teardown (Option A).
#     Runs after **every** job, even if the deploy failed.
# ─────────────────────────────────────────────────────────────
  cleanup:
    if: ${{ inputs.cleanup_after_run }}
    needs: deploy
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION:            ${{ needs.deploy.outputs.AWS_REGION }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init (remote state)
        working-directory: infra/database-aws
        run: terraform init -input=false

      - name: Destroy stack
        working-directory: infra/database-aws
        run: terraform destroy -auto-approve -input=false
