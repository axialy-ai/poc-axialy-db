name: Axialy DB AWS
on:
  workflow_dispatch:
    inputs:
      db_identifier:
        required: true
        default: axialy-database-cluster
      aws_region:
        required: true
        default: us-west-1
      instance_class:
        required: true
        default: db.t3.micro
      allocated_storage:
        required: true
        default: "20"
      #
      # ── NEW toggles ────────────────────────────────────────────────
      #
      cleanup_after_run:
        description: "Destroy the stack (Option A)"
        type: boolean
        default: false
      import_existing:
        description: "Auto‑import pre‑existing resources (Option B)"
        type: boolean
        default: true

env:
  AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

########################################################################
# 1)  PREPARE  ─────────────────────────────────────────────────────────
#      • validate / normalise region
#      • configure creds
#      • guarantee remote‑state backend
#      • purge remnant VPCs, NAT EIPs & duplicate SSM parameters
########################################################################
jobs:
  prepare:
    runs-on: ubuntu-latest

    outputs:
      aws_region: ${{ steps.region.outputs.aws_region }}

    steps:
      - uses: actions/checkout@v4

      # ── Region sanitiser ───────────────────────────────────────────
      - name: Normalise AWS region input
        id: region
        shell: bash
        run: |
          REGION_IN="${{ github.event.inputs.aws_region }}"
          REGION_CLEAN="$(printf "%s" "$REGION_IN" | tr '–—−‑' '-')"
          [[ "$REGION_CLEAN" =~ ^[a-z]{2}-[a-z]+-[0-9]+$ ]] \
            || { echo "::error::Invalid AWS region"; exit 1; }

          echo "AWS_REGION=$REGION_CLEAN"          >> "$GITHUB_ENV"
          echo "AWS_DEFAULT_REGION=$REGION_CLEAN"  >> "$GITHUB_ENV"
          echo "aws_region=$REGION_CLEAN"          >> "$GITHUB_OUTPUT"

      # ── AWS credentials ────────────────────────────────────────────
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ steps.region.outputs.aws_region }}

      # ── Remote‑state bucket & lock table ───────────────────────────
      - name: Ensure remote‑state bucket & lock table exist
        shell: bash
        run: |
          BUCKET=axialy-tf-state
          LOCK_TABLE=axialy-tf-lock

          aws s3 mb "s3://$BUCKET" 2>/dev/null || true

          aws dynamodb create-table \
            --table-name "$LOCK_TABLE" \
            --attribute-definitions  AttributeName=LockID,AttributeType=S \
            --key-schema            AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST 2>/dev/null || true

          echo "TF_BUCKET=$BUCKET"     >> "$GITHUB_ENV"
          echo "TF_LOCK_TABLE=$LOCK_TABLE" >> "$GITHUB_ENV"

      # ── Pre‑flight cleanup  (quotas & idempotency) ─────────────────
      - name: Pre‑flight cleanup (remnant VPCs, EIPs, params)
        shell: bash
        env:
          REGION: ${{ steps.region.outputs.aws_region }}
        run: |
          set -euo pipefail
          echo "🔍 Removing orphan Axialy VPCs…"
          for vpc in $(aws ec2 describe-vpcs \
                --filters "Name=tag:ManagedBy,Values=terraform" \
                          "Name=tag:Name,Values=axialy-*" \
                --query 'Vpcs[].VpcId' --output text); do
            echo "🗑️  VPC $vpc"
            # NAT gateways (they keep EIPs busy)
            for ngw in $(aws ec2 describe-nat-gateways \
                      --filter Name=vpc-id,Values=$vpc \
                      --query 'NatGateways[].NatGatewayId' --output text); do
              aws ec2 delete-nat-gateway --nat-gateway-id "$ngw" || true
            done
            # wait a bit so attached EIPs detach
            sleep 10
            # Internet gateways
            for igw in $(aws ec2 describe-internet-gateways \
                       --filters Name=attachment.vpc-id,Values=$vpc \
                       --query 'InternetGateways[].InternetGatewayId' --output text); do
              aws ec2 detach-internet-gateway --internet-gateway-id "$igw" --vpc-id "$vpc" || true
              aws ec2 delete-internet-gateway --internet-gateway-id "$igw" || true
            done
            # Subnets
            for subnet in $(aws ec2 describe-subnets --filters Name=vpc-id,Values=$vpc \
                               --query 'Subnets[].SubnetId' --output text); do
              aws ec2 delete-subnet --subnet-id "$subnet" || true
            done
            # Route tables (non‑main)
            for rtb in $(aws ec2 describe-route-tables --filters Name=vpc-id,Values=$vpc \
                       --query 'RouteTables[?Associations[?Main==`false`]].RouteTableId' --output text); do
              aws ec2 delete-route-table --route-table-id "$rtb" || true
            done
            aws ec2 delete-vpc --vpc-id "$vpc" || true
          done

          echo "🔍 Releasing orphan Axialy EIPs…"
          for alloc in $(aws ec2 describe-addresses \
                     --filters "Name=tag:Name,Values=axialy-nat-eip-*" \
                     --query 'Addresses[].AllocationId' --output text); do
            aws ec2 release-address --allocation-id "$alloc" || true
          done

          echo "🔍 Deleting duplicate SSM parameters to avoid PutParameter collisions…"
          for p in host port user password; do
            NAME="/axialy/database/${p}"
            aws ssm delete-parameter --name "$NAME" 2>/dev/null || true
          done

########################################################################
# 2)  DEPLOY  ──────────────────────────────────────────────────────────
########################################################################
  deploy:
    needs: prepare
    runs-on: ubuntu-latest

    env:
      AWS_REGION:            ${{ needs.prepare.outputs.aws_region }}
      AWS_DEFAULT_REGION:    ${{ needs.prepare.outputs.aws_region }}
      TF_BUCKET:             ${{ env.TF_BUCKET }}
      TF_LOCK_TABLE:         ${{ env.TF_LOCK_TABLE }}
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init
        working-directory: infra/database-aws
        run: |
          cat > backend.tf <<EOF
          terraform {
            backend "s3" {
              bucket         = "${TF_BUCKET}"
              key            = "database-aws/terraform.tfstate"
              region         = "${AWS_REGION}"
              dynamodb_table = "${TF_LOCK_TABLE}"
              encrypt        = true
            }
          }
          EOF
          terraform init -input=false

      # ── Option B – import resources that may already exist ─────────
      - name: Import existing resources (if enabled)
        if: ${{ github.event.inputs.import_existing }}
        shell: bash
        working-directory: infra/database-aws
        run: |
          set -euo pipefail
          DB_ID="${{ github.event.inputs.db_identifier }}"

          imp () {
            local addr=$1 id=$2
            if ! terraform state list | grep -q "^$addr$"; then
              echo "› importing $addr ($id)"
              terraform import "$addr" "$id" || true
            fi
          }

          # Subnet group
          if aws rds describe-db-subnet-groups \
                --db-subnet-group-name axialy-db-subnet-group >/dev/null 2>&1; then
            imp aws_db_subnet_group.axialy axialy-db-subnet-group
          fi

          # CloudWatch log groups
          for lg in error general slowquery; do
            NAME="/aws/rds/instance/${DB_ID}/${lg}"
            if aws logs describe-log-groups \
                  --log-group-name-prefix "$NAME" | jq -e '.logGroups|length>0' >/dev/null; then
              imp "aws_cloudwatch_log_group.rds_${lg}" "$NAME"
            fi
          done

          # Orphaned NAT EIPs
          for i in 1 2; do
            ALLOC=$(aws ec2 describe-addresses \
                     --filters "Name=tag:Name,Values=axialy-nat-eip-${i}" \
                     --query 'Addresses[0].AllocationId' --output text 2>/dev/null || true)
            [ "$ALLOC" != "None" ] && imp "aws_eip.nat[${i-1}]" "$ALLOC"
          done

          # KMS alias (avoid AlreadyExistsException)
          if aws kms list-aliases --query 'Aliases[?AliasName==`alias/axialy-rds`].AliasName' --output text | grep -q 'alias/axialy-rds'; then
            ARN=$(aws kms list-aliases --query 'Aliases[?AliasName==`alias/axialy-rds`].AliasArn' --output text)
            imp aws_kms_alias.rds "$ARN"
          fi

      # ── Terraform apply ────────────────────────────────────────────
      - name: Terraform apply
        id: tfout
        working-directory: infra/database-aws
        run: |
          terraform apply -auto-approve -input=false \
            -var="db_identifier=${{ github.event.inputs.db_identifier }}" \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="instance_class=${{ github.event.inputs.instance_class }}" \
            -var="allocated_storage=${{ github.event.inputs.allocated_storage }}"

          echo "db_endpoint=$(terraform output -raw db_endpoint)"        >> "$GITHUB_OUTPUT"
          echo "db_port=$(terraform output -raw db_port)"                >> "$GITHUB_OUTPUT"
          echo "db_admin_user=$(terraform output -raw db_admin_user)"    >> "$GITHUB_OUTPUT"
          echo "db_admin_password=$(terraform output -raw db_admin_password)" >> "$GITHUB_OUTPUT"

########################################################################
# 3)  CLEAN‑UP  (OPTIONAL) ─────────────────────────────────────────────
########################################################################
  cleanup:
    if: ${{ github.event.inputs.cleanup_after_run }}
    needs: [prepare, deploy]
    runs-on: ubuntu-latest

    env:
      AWS_REGION:            ${{ needs.prepare.outputs.aws_region }}
      AWS_DEFAULT_REGION:    ${{ needs.prepare.outputs.aws_region }}
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      TF_BUCKET:             ${{ env.TF_BUCKET }}
      TF_LOCK_TABLE:         ${{ env.TF_LOCK_TABLE }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init (remote state)
        working-directory: infra/database-aws
        run: terraform init -input=false

      - name: Destroy stack
        working-directory: infra/database-aws
        run: terraform destroy -auto-approve -input=false
