# ── .github/workflows/axialy_db_aws.yml ───────────────────────────────────────
name: Axialy DB AWS

on:
  workflow_dispatch:
    inputs:
      db_identifier:
        required: true
        default: axialy-database-cluster
      aws_region:
        required: true
        default: us-west-1
      instance_class:
        required: true
        default: db.t3.micro
      allocated_storage:
        required: true
        default: "20"

      # ── Toggle flags ──────────────────────────────────────────────
      cleanup_after_run:
        description: "Destroy the stack once the run is finished (Option A)"
        type: boolean
        default: false
      import_existing:
        description: "Try to import any pre‑existing resources (Option B)"
        type: boolean
        default: true

env:
  AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

###############################################################################
# 1)  PREPARE – region validation, creds, backend guarantee, deep clean‑up
###############################################################################
jobs:
  prepare:
    runs-on: ubuntu-latest

    outputs:
      aws_region:   ${{ steps.region.outputs.aws_region }}
      tf_bucket:    ${{ steps.state.outputs.tf_bucket }}
      tf_lock_tbl:  ${{ steps.state.outputs.tf_lock_tbl }}

    steps:
      - uses: actions/checkout@v4

      # ── Region normaliser ─────────────────────────────────────────
      - name: Normalise AWS region input
        id: region
        shell: bash
        run: |
          REGION_IN="${{ github.event.inputs.aws_region }}"
          REGION_CLEAN="$(printf '%s' "$REGION_IN" | tr '–—−‑' '-')"
          [[ "$REGION_CLEAN" =~ ^[a-z]{2}-[a-z]+-[0-9]+$ ]] \
            || { echo "::error::Invalid AWS region"; exit 1; }

          echo "AWS_REGION=$REGION_CLEAN"          >> "$GITHUB_ENV"
          echo "AWS_DEFAULT_REGION=$REGION_CLEAN"  >> "$GITHUB_ENV"
          echo "aws_region=$REGION_CLEAN"          >> "$GITHUB_OUTPUT"

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ steps.region.outputs.aws_region }}

      # ── S3 & DynamoDB backend (and surface as job outputs) ────────
      - name: Ensure remote‑state backend exists
        id: state
        shell: bash
        run: |
          BUCKET=axialy-tf-state
          LOCK_TABLE=axialy-tf-lock

          aws s3 mb "s3://${BUCKET}" 2>/dev/null || true
          aws dynamodb create-table \
              --table-name "$LOCK_TABLE" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema            AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST 2>/dev/null || true

          echo "TF_BUCKET=$BUCKET"          >> "$GITHUB_ENV"
          echo "TF_LOCK_TABLE=$LOCK_TABLE"  >> "$GITHUB_ENV"
          echo "tf_bucket=$BUCKET"          >> "$GITHUB_OUTPUT"
          echo "tf_lock_tbl=$LOCK_TABLE"    >> "$GITHUB_OUTPUT"

      # ── Deep hygiene – bullet‑proof VPC purge & quota checks ──────
      - name: Deep cleanup (orphan VPCs, NAT EIPs, ENIs, endpoints, KMS alias)
        shell: bash
        env:
          AWS_PAGER: ""
        run: |
          set -euo pipefail

          ##################################################################
          # 0) Quota sanity check – request a bump *and* make sure we end up
          #    below the current soft‑limit before Terraform runs.
          ##################################################################
          echo "🔎 Checking regional VPC quota utilisation …"
          SERVICE_CODE="vpc"
          QUOTA_CODE="L-F678F1CE"   # "VPCs per Region"
          CUR_VPCS=$(aws ec2 describe-vpcs --query 'length(Vpcs)' --output text)
          LIMIT_RAW=$(aws service-quotas get-service-quota \
                        --service-code "$SERVICE_CODE" \
                        --quota-code   "$QUOTA_CODE" \
                        --query 'Quota.Value' --output text)
          CUR_LIMIT=${LIMIT_RAW%%.*}   # "5.0" → "5" ; leaves "5" untouched
          echo "• Current usage: ${CUR_VPCS}/${CUR_LIMIT}"

          if [ "$CUR_VPCS" -ge "$CUR_LIMIT" ]; then
            DESIRED=$(( CUR_LIMIT + 5 ))
            echo "⚠️  VPC quota maxed‑out – requesting raise to ${DESIRED}"
            aws service-quotas request-service-quota-increase \
                 --service-code "$SERVICE_CODE" \
                 --quota-code   "$QUOTA_CODE" \
                 --desired-value "$DESIRED" 2>/dev/null || true
          fi

          ##################################################################
          # 1) Remove stale KMS alias up‑front so Terraform can recreate it
          ##################################################################
          if aws kms list-aliases \
               --query 'Aliases[?AliasName==`alias/axialy-rds`]' \
               --output text | grep -q 'alias/axialy-rds'; then
            echo "🗑️  Deleting stale KMS alias/axialy-rds"
            aws kms delete-alias --alias-name alias/axialy-rds
          fi

          ##################################################################
          # 2) Purge every Axialy‑tagged VPC and **wait** for *all* children
          ##################################################################
          orphan_vpcs=$(aws ec2 describe-vpcs \
                       --filters "Name=tag:Name,Values=axialy-*" \
                       --query 'Vpcs[].VpcId' --output text || true)

          for vpc in $orphan_vpcs; do
            echo "::group::🧹 Full purge of $vpc"

            # ── 2.1 NAT Gateways & their EIPs (+ ENIs wait) ───────────────
            for ngw in $(aws ec2 describe-nat-gateways \
                           --filter Name=vpc-id,Values=$vpc \
                           --query 'NatGateways[].NatGatewayId' \
                           --output text || true); do
              echo "• Deleting NAT Gateway $ngw"
              alloc=$(aws ec2 describe-nat-gateways --nat-gateway-ids "$ngw" \
                       --query 'NatGateways[0].NatGatewayAddresses[0].AllocationId' \
                       --output text || true)
              aws ec2 delete-nat-gateway --nat-gateway-id "$ngw" || true

              # Wait for the gateway itself to show 'deleted'
              for _ in {1..60}; do
                state=$(aws ec2 describe-nat-gateways --nat-gateway-ids "$ngw" \
                         --query 'NatGateways[0].State' --output text 2>/dev/null || true)
                [[ "$state" == "deleted" || "$state" == "None" ]] && break
                sleep 5
              done

              # Wait for residual ENIs created by the NAT‑GW to vanish
              gw_enis=$(aws ec2 describe-network-interfaces \
                           --filters Name=attachment.nat-gateway-id,Values=$ngw \
                           --query 'NetworkInterfaces[].NetworkInterfaceId' \
                           --output text || true)
              if [ -n "$gw_enis" ] && [ "$gw_enis" != "None" ]; then
                echo "  ↪ waiting on ENIs $gw_enis"
                aws ec2 wait network-interface-deleted --network-interface-ids $gw_enis || true
              fi

              [ -n "${alloc:-}" ] && aws ec2 release-address --allocation-id "$alloc" 2>/dev/null || true
            done

            # ── 2.2 VPC interface‑endpoints & wait loop ───────────────────
            for vpce in $(aws ec2 describe-vpc-endpoints \
                            --filters Name=vpc-id,Values=$vpc \
                            --query 'VpcEndpoints[].VpcEndpointId' \
                            --output text || true); do
              echo "• Deleting VPC Endpoint $vpce"
              aws ec2 delete-vpc-endpoints --vpc-endpoint-ids "$vpce" || true

              # manual waiter (CLI lacks vpc-endpoint-deleted)
              for _ in {1..60}; do
                aws ec2 describe-vpc-endpoints --vpc-endpoint-ids "$vpce" >/dev/null 2>&1 \
                  || { echo "  ↪ $vpce gone"; break; }
                sleep 5
              done
            done

            # ── 2.3 Detach & delete IGWs ─────────────────────────────────
            for igw in $(aws ec2 describe-internet-gateways \
                           --filters Name=attachment.vpc-id,Values=$vpc \
                           --query 'InternetGateways[].InternetGatewayId' \
                           --output text || true); do
              echo "• Deleting IGW $igw"
              aws ec2 detach-internet-gateway --internet-gateway-id "$igw" \
                                              --vpc-id "$vpc" || true
              aws ec2 delete-internet-gateway  --internet-gateway-id "$igw" || true
            done

            # ── 2.4 Custom NACLs ─────────────────────────────────────────
            for nacl in $(aws ec2 describe-network-acls \
                            --filters Name=vpc-id,Values=$vpc \
                            --query 'NetworkAcls[?IsDefault==`false`].NetworkAclId' \
                            --output text || true); do
              echo "• Deleting NACL $nacl"
              aws ec2 delete-network-acl --network-acl-id "$nacl" || true
            done

            # ── 2.5 Subnet route‑table associations & tables ─────────────
            for rta in $(aws ec2 describe-route-tables \
                           --filters Name=vpc-id,Values=$vpc \
                           --query 'RouteTables[].Associations[?Main==`false`].RouteTableAssociationId' \
                           --output text || true); do
              aws ec2 disassociate-route-table --association-id "$rta" || true
            done
            for rtb in $(aws ec2 describe-route-tables \
                           --filters Name=vpc-id,Values=$vpc \
                           --query 'RouteTables[?Associations[?Main==`false`]].RouteTableId' \
                           --output text || true); do
              echo "• Deleting Route Table $rtb"
              aws ec2 delete-route-table --route-table-id "$rtb" || true
            done

            # ── 2.6 Subnets ─────────────────────────────────────────────
            for subnet in $(aws ec2 describe-subnets \
                              --filters Name=vpc-id,Values=$vpc \
                              --query 'Subnets[].SubnetId' --output text || true); do
              echo "• Deleting Subnet $subnet"
              aws ec2 delete-subnet --subnet-id "$subnet" || true
            done

            # ── 2.7 Non‑default Security Groups ─────────────────────────
            for sg in $(aws ec2 describe-security-groups \
                           --filters Name=vpc-id,Values=$vpc \
                           --query 'SecurityGroups[?GroupName!=`default`].GroupId' \
                           --output text || true); do
              echo "• Deleting Security Group $sg"
              aws ec2 delete-security-group --group-id "$sg" || true
            done

            # ── 2.8 Any remaining *available* ENIs ──────────────────────
            for eni in $(aws ec2 describe-network-interfaces \
                           --filters Name=vpc-id,Values=$vpc Name=status,Values=available \
                           --query 'NetworkInterfaces[].NetworkInterfaceId' \
                           --output text || true); do
              echo "• Deleting ENI $eni"
              aws ec2 delete-network-interface --network-interface-id "$eni" || true
            done

            # Wait until ENI count is zero (defensive)
            for _ in {1..24}; do
              residual=$(aws ec2 describe-network-interfaces \
                           --filters Name=vpc-id,Values=$vpc \
                           --query 'length(NetworkInterfaces)' --output text)
              [ "$residual" -eq 0 ] && break
              echo "  ↪ $residual ENI(s) still present … waiting"; sleep 5
            done

            # ── 2.9 Delete the VPC with retry guard ────────────────────
            echo "• Deleting VPC $vpc"
            for try in {1..12}; do
              aws ec2 delete-vpc --vpc-id "$vpc" && { echo "✔️  $vpc deleted"; break; }
              echo "  ↪ dependency still present – retry $try/12"; sleep 10
            done

            echo "::endgroup::"
          done
###############################################################################
# 2)  DEPLOY – create / update the entire stack (Terraform apply)
###############################################################################
  deploy:
    needs: prepare
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION:            ${{ needs.prepare.outputs.aws_region }}
      AWS_DEFAULT_REGION:    ${{ needs.prepare.outputs.aws_region }}
      TF_BUCKET:             ${{ needs.prepare.outputs.tf_bucket }}
      TF_LOCK_TABLE:         ${{ needs.prepare.outputs.tf_lock_tbl }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init
        working-directory: infra/database-aws
        run: |
          cat > backend.tf <<EOF
          terraform {
            backend "s3" {
              bucket         = "${TF_BUCKET}"
              key            = "database-aws/terraform.tfstate"
              region         = "${AWS_REGION}"
              dynamodb_table = "${TF_LOCK_TABLE}"
              encrypt        = true
            }
          }
          EOF
          terraform init -input=false

      # ── (Option B) Import any pre‑existing pieces ─────────────────
      - name: Import existing resources (if enabled)
        if: ${{ github.event.inputs.import_existing }}
        working-directory: infra/database-aws
        shell: bash
        run: |
          set -euo pipefail
          DB_ID="${{ github.event.inputs.db_identifier }}"

          imp () {
            local addr=$1 id=$2
            if ! terraform state list | grep -q "^$addr$"; then
              echo "› importing $addr ($id)"
              terraform import "$addr" "$id" || true
            fi
          }

          # Subnet‑group
          aws rds describe-db-subnet-groups \
              --db-subnet-group-name axialy-db-subnet-group >/dev/null 2>&1 \
              && imp aws_db_subnet_group.axialy axialy-db-subnet-group

          # Log groups
          for lg in error general slowquery; do
            NAME="/aws/rds/instance/${DB_ID}/${lg}"
            aws logs describe-log-groups \
                 --log-group-name-prefix "$NAME" | jq -e '.logGroups|length>0' >/dev/null 2>&1 \
                 && imp "aws_cloudwatch_log_group.rds_${lg}" "$NAME"
          done

          # NAT EIPs
          for i in 1 2; do
            ALLOC=$(aws ec2 describe-addresses \
                      --filters "Name=tag:Name,Values=axialy-nat-eip-${i}" \
                      --query 'Addresses[0].AllocationId' --output text 2>/dev/null || true)
            [ "$ALLOC" != "None" ] && imp "aws_eip.nat[$((i-1))]" "$ALLOC"
          done

      # ── Terraform apply ───────────────────────────────────────────
      - name: Terraform apply
        id: tfout
        working-directory: infra/database-aws
        run: |
          terraform apply -auto-approve -input=false \
            -var="db_identifier=${{ github.event.inputs.db_identifier }}" \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="instance_class=${{ github.event.inputs.instance_class }}" \
            -var="allocated_storage=${{ github.event.inputs.allocated_storage }}"

          echo "db_endpoint=$(terraform output -raw db_endpoint)"            >> "$GITHUB_OUTPUT"
          echo "db_port=$(terraform output -raw db_port)"                    >> "$GITHUB_OUTPUT"
          echo "db_admin_user=$(terraform output -raw db_admin_user)"        >> "$GITHUB_OUTPUT"
          echo "db_admin_password=$(terraform output -raw db_admin_password)" >> "$GITHUB_OUTPUT"

###############################################################################
# 3)  CLEANUP – optional auto‑destroy when cleanup_after_run=true
###############################################################################
  cleanup:
    if: ${{ github.event.inputs.cleanup_after_run }}
    needs: [prepare, deploy]
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION:            ${{ needs.prepare.outputs.aws_region }}
      AWS_DEFAULT_REGION:    ${{ needs.prepare.outputs.aws_region }}
      TF_BUCKET:             ${{ needs.prepare.outputs.tf_bucket }}
      TF_LOCK_TABLE:         ${{ needs.prepare.outputs.tf_lock_tbl }}

    steps:
      - uses: actions/checkout@v4

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6
          terraform_wrapper: false

      - name: Terraform init (remote state)
        working-directory: infra/database-aws
        run: |
          cat > backend.tf <<EOF
          terraform {
            backend "s3" {
              bucket         = "${TF_BUCKET}"
              key            = "database-aws/terraform.tfstate"
              region         = "${AWS_REGION}"
              dynamodb_table = "${TF_LOCK_TABLE}"
              encrypt        = true
            }
          }
          EOF
          terraform init -input=false

      - name: Destroy stack
        working-directory: infra/database-aws
        run: terraform destroy -auto-approve -input=false
